# -*- coding: utf-8 -*-
from playwright.sync_api import sync_playwright
import time
import re
import datetime
from typing import List, Dict, Optional

# ============== å…±é€šãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ==============

VERBOSE = True

def log(msg: str):
    if VERBOSE:
        print(msg)

def text_clean(s: str) -> str:
    import re
    return re.sub(r"\s+", " ", (s or "")).strip()

def extract_mid(s: str) -> Optional[str]:
    """URLã‹ã‚‰ mid ã‚’æŠ½å‡º"""
    if not s:
        return None
    s = str(s).strip()
    m = re.search(r"[?&#]mid=([A-Za-z0-9]+)", s)
    if m:
        return m.group(1)
    m = re.search(r"/match/([A-Za-z0-9]{6,20})(?:/|$)", s)
    if m:
        return m.group(1)
    return None

# ============== ä»Šå›ã® HEADER ==============

HEADER_SCHEDULED = [
    "è©¦åˆå›½åŠã³ã‚«ãƒ†ã‚´ãƒª","è©¦åˆäºˆå®šæ™‚é–“","ãƒ›ãƒ¼ãƒ é †ä½","ã‚¢ã‚¦ã‚§ãƒ¼é †ä½","ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ ","ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ ",
    "ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ æœ€å¤§å¾—ç‚¹å–å¾—è€…","ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ æœ€å¤§å¾—ç‚¹å–å¾—è€…",
    "ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ ãƒ›ãƒ¼ãƒ å¾—ç‚¹","ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ ãƒ›ãƒ¼ãƒ å¤±ç‚¹","ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ ãƒ›ãƒ¼ãƒ å¾—ç‚¹","ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ ãƒ›ãƒ¼ãƒ å¤±ç‚¹",
    "ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ ã‚¢ã‚¦ã‚§ãƒ¼å¾—ç‚¹","ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ ã‚¢ã‚¦ã‚§ãƒ¼å¤±ç‚¹",
    "ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ ã‚¢ã‚¦ã‚§ãƒ¼å¾—ç‚¹","ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ ã‚¢ã‚¦ã‚§ãƒ¼å¤±ç‚¹","è©¦åˆãƒªãƒ³ã‚¯æ–‡å­—åˆ—","ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚é–“"
]

# ============== Flashscoreã€Œé–‹å‚¬äºˆå®šã€ãƒŠãƒ“ ==============

def goto_football_top(page):
    """ã‚µãƒƒã‚«ãƒ¼ â†’ é–‹å‚¬äºˆå®šã‚¿ãƒ–ã¸é·ç§»"""
    log("ğŸŒ Flashscore ãƒˆãƒƒãƒ—ã¸ã‚¢ã‚¯ã‚»ã‚¹...")
    page.goto("https://www.flashscore.co.jp/", timeout=45000, wait_until="domcontentloaded")

    # CookieãƒãƒŠãƒ¼ãªã©
    try:
        page.locator("#onetrust-accept-btn-handler").click(timeout=2000)
        log("âœ… CookieãƒãƒŠãƒ¼ã‚’é–‰ã˜ã¾ã—ãŸ")
    except:
        pass

    # ã‚µãƒƒã‚«ãƒ¼ãŒé¸ã°ã‚Œã¦ã„ãªã„å ´åˆã«å‚™ãˆã¦ã€Œã‚µãƒƒã‚«ãƒ¼ã€ã‚¯ãƒªãƒƒã‚¯ï¼ˆã ã„ãŸã„ä¸è¦ã ã‘ã©ä¿é™ºï¼‰
    try:
        soccer_btn = page.locator("a,button").filter(has_text="ã‚µãƒƒã‚«ãƒ¼").first
        if soccer_btn and soccer_btn.count():
            soccer_btn.click(timeout=4000)
            time.sleep(0.8)
    except:
        pass

    # ã€Œé–‹å‚¬äºˆå®šã€ã‚¿ãƒ–ã‚’ã‚¯ãƒªãƒƒã‚¯
    try:
        # data-analytics-alias='scheduled' ãŒæœ€å„ªå…ˆ
        tab = page.locator("div.filters__tab[data-analytics-alias='scheduled']").first
        if tab and tab.count():
            tab.click(timeout=4000)
        else:
            # ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯
            tab = page.locator("div.filters__tab").filter(
                has_text=re.compile(r"(é–‹å‚¬äºˆå®š)")
            ).first
            tab.click(timeout=4000)
        log("âœ… ã€é–‹å‚¬äºˆå®šã€ã‚¿ãƒ–ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")
    except Exception as e:
        log(f"âš ï¸ é–‹å‚¬äºˆå®šã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆå¤±æ•—: {e}")

    # è©¦åˆè¡ŒãŒæç”»ã•ã‚Œã‚‹ã¾ã§å°‘ã—å¾…ã¤
    try:
        page.wait_for_timeout(1000)
        page.wait_for_load_state("networkidle", timeout=8000)
    except:
        pass

def expand_all_collapsed_leagues(page):
    """
    Flashscoreã€é–‹å‚¬äºˆå®šã€ã‚¿ãƒ–ã§ã€
    æŠ˜ã‚ŠãŸãŸã¾ã‚Œã¦ã„ã‚‹ãƒªãƒ¼ã‚°ï¼ˆï¼ãƒªãƒ¼ã‚°å…¨è©¦åˆãŒéè¡¨ç¤ºï¼‰ã‚’ã™ã¹ã¦å±•é–‹ã™ã‚‹ã€‚
    """
    print("ğŸ“‚ æŠ˜ã‚ŠãŸãŸã¿ãƒªãƒ¼ã‚°ï¼ˆéè¡¨ç¤ºï¼‰ã‚’å±•é–‹ã—ã¾ã™...")

    # ã€Œãƒªãƒ¼ã‚°å…¨è©¦åˆ è¡¨ç¤ºã€ãƒœã‚¿ãƒ³ = ä»Šã¯éè¡¨ç¤ºãªã®ã§æŠ¼ã™ã¨è¡¨ç¤ºã«ãªã‚‹
    # â€» å®Œå…¨ä¸€è‡´ã«ã™ã‚‹ã“ã¨ï¼ï¼ "*='è¡¨ç¤º'" ã¯ã€Œéè¡¨ç¤ºã€ã«ã‚‚ãƒãƒƒãƒã—ã¦ã—ã¾ã†
    btn_selector = (
        "button[data-testid='wcl-accordionButton']"
        "[aria-label='ãƒªãƒ¼ã‚°å…¨è©¦åˆ è¡¨ç¤º']"
    )
    # äºˆå‚™ã§ svg ã®ãƒ†ã‚¹ãƒˆIDã‚’ä½¿ã†æ›¸ãæ–¹ï¼ˆå¿…è¦ãªã‚‰å·®ã—æ›¿ãˆï¼‰
    # btn_selector = (
    #     "button[data-testid='wcl-accordionButton']"
    #     ":has(svg[data-testid='wcl-icon-action-navigation-arrow-down'])"
    # )

    max_loops = 200  # å¿µã®ãŸã‚å®‰å…¨å¼

    for _ in range(max_loops):
        btns = page.locator(btn_selector)
        count = btns.count()

        if count == 0:
            print("   âœ… ã™ã¹ã¦ã®æŠ˜ã‚ŠãŸãŸã¿ãƒªãƒ¼ã‚°ã‚’å±•é–‹ã—ã¾ã—ãŸ")
            return

        print(f"   æ®‹ã‚Šã€è¡¨ç¤ºã€ãƒœã‚¿ãƒ³æ•°: {count}")

        btn = btns.first

        try:
            btn.scroll_into_view_if_needed()
        except Exception:
            pass

        try:
            btn.click(timeout=2000)
        except Exception as e:
            print(f"   âš ï¸ ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯å¤±æ•—: {e}")
            break

        # éåŒæœŸå±•é–‹å¾…ã¡
        page.wait_for_timeout(200)

    print("   âš ï¸ ãƒ«ãƒ¼ãƒ—ä¸Šé™ã«é”ã—ã¾ã—ãŸã€‚ã¾ã éè¡¨ç¤ºãƒªãƒ¼ã‚°ãŒæ®‹ã£ã¦ã„ã‚‹å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")

def _get_match_row_category(row):
    """
    1ã¤ã®è©¦åˆè¡Œã‹ã‚‰ã€Œè©¦åˆå›½åŠã³ã‚«ãƒ†ã‚´ãƒªã€ï¼ˆå›½: ãƒªãƒ¼ã‚°ï¼‰ã‚’æ¨å®šã€‚
    DOMæ§‹é€ ãŒå¤‰ã‚ã‚‹å¯èƒ½æ€§ãŒã‚ã‚‹ã®ã§ã€å¿…è¦ã«å¿œã˜ã¦å¾®èª¿æ•´ã—ã¦ãã ã•ã„ã€‚
    """
    # ç¥–å…ˆã®ã‚°ãƒ«ãƒ¼ãƒ—ã‹ã‚‰ãƒ˜ãƒƒãƒ€ãƒ†ã‚­ã‚¹ãƒˆã‚’å–å¾—ã™ã‚‹ã‚¤ãƒ¡ãƒ¼ã‚¸
    try:
        header = row.locator(
            "xpath=ancestor::div[contains(@class,'event__group')]//div[contains(@class,'event__title')]"
        ).first
        if not header.count():
            return ""

        country = ""
        league = ""

        try:
            country = text_clean(
                header.locator(".event__title--country").first.text_content() or ""
            )
        except:
            pass

        try:
            league = text_clean(
                header.locator(".event__title--type").first.text_content() or ""
            )
        except:
            pass

        if not country and not league:
            # ãƒ˜ãƒƒãƒ€ã®ç´ ãƒ†ã‚­ã‚¹ãƒˆã‚’ fallback ã«ã™ã‚‹
            txt = text_clean(header.text_content() or "")
            return txt

        if country and league:
            return f"{country}: {league}"
        return country or league
    except:
        return ""

def _get_match_row_teams_and_time(row):
    """
    1ã¤ã®è©¦åˆè¡Œã‹ã‚‰
      - è©¦åˆäºˆå®šæ™‚é–“
      - ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ å
      - ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ å
    ã‚’æŠ½å‡ºï¼ˆæ—§UI / æ–°UI ä¸¡å¯¾å¿œï¼‰
    """
    # ===== æ™‚é–“ =====
    ktime = ""

    # æ—§UI: .event__time
    try:
        ktime = text_clean(row.locator(".event__time").first.text_content() or "")
    except Exception:
        pass

    # æ–°UI: data-testid ãƒ™ãƒ¼ã‚¹
    if not ktime:
        try:
            ktime = text_clean(
                row.locator(
                    "[data-testid='wcl-time'], "
                    "[data-testid='wcl-start-time'], "
                    "[data-testid='wcl-time-status']"
                ).first.text_content() or ""
            )
        except Exception:
            pass

    # ===== ãƒãƒ¼ãƒ å =====
    home = ""
    away = ""

    # ãƒ‘ã‚¿ãƒ¼ãƒ³â‘ : æ—§UI (.event__participant--home / --away)
    try:
        h = row.locator(".event__participant--home .event__participant--name").first
        a = row.locator(".event__participant--away .event__participant--name").first
        if h.count():
            home = text_clean(h.text_content() or "")
        if a.count():
            away = text_clean(a.text_content() or "")
    except Exception:
        pass

    # ãƒ‘ã‚¿ãƒ¼ãƒ³â‘¡: æ—§UI ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ (.event__participant)
    if not home or not away:
        try:
            ps = row.locator(".event__participant .event__participant--name")
            if ps.count() >= 2:
                if not home:
                    home = text_clean(ps.first.text_content() or "")
                if not away:
                    away = text_clean(ps.last.text_content() or "")
        except Exception:
            pass

    # ãƒ‘ã‚¿ãƒ¼ãƒ³â‘¢: æ–°UI æ˜ç¤ºçš„ã‚»ãƒ¬ã‚¯ã‚¿
    #   <div class="wcl-participant_bctDY event__homeParticipant" ...>
    #       <span class="wcl-name_jjfMf" data-testid="wcl-scores-simple-text-01">...</span>
    #   </div>
    if not home or not away:
        try:
            h = row.locator(
                ".event__homeParticipant span.wcl-name_jjfMf, "
                ".event__homeParticipant [data-testid='wcl-scores-simple-text-01']"
            ).first
            a = row.locator(
                ".event__awayParticipant span.wcl-name_jjfMf, "
                ".event__awayParticipant [data-testid='wcl-scores-simple-text-01']"
            ).first

            if h and h.count():
                if not home:
                    home = text_clean(h.text_content() or "")
            if a and a.count():
                if not away:
                    away = text_clean(a.text_content() or "")
        except Exception:
            pass

    # ãƒ‘ã‚¿ãƒ¼ãƒ³â‘£: æ–°UI ã•ã‚‰ã«ã‚†ã‚‹ãã€å…¨ participant ã‹ã‚‰å…ˆé ­/æœ«å°¾
    if not home or not away:
        try:
            ps = row.locator(
                "[data-testid='wcl-matchRow-participant'] span.wcl-name_jjfMf, "
                "[data-testid='wcl-matchRow-participant'] [data-testid='wcl-scores-simple-text-01']"
            )
            n = ps.count()
            if n >= 2:
                if not home:
                    home = text_clean(ps.nth(0).text_content() or "")
                if not away:
                    away = text_clean(ps.nth(n - 1).text_content() or "")
        except Exception:
            pass

    # ãƒ‘ã‚¿ãƒ¼ãƒ³â‘¤: æœ€å¾Œã®æœ€å¾Œã« <img alt="ãƒãƒ¼ãƒ å"> ã‚’ä½¿ã†ï¼ˆä¿é™ºï¼‰
    if not home or not away:
        try:
            imgs = row.locator("[data-testid='wcl-matchRow-participant'] img[data-testid='wcl-participantLogo']")
            n_img = imgs.count()
            if n_img >= 2:
                if not home:
                    alt0 = imgs.nth(0).get_attribute("alt") or ""
                    home = text_clean(alt0)
                if not away:
                    alt1 = imgs.nth(n_img - 1).get_attribute("alt") or ""
                    away = text_clean(alt1)
        except Exception:
            pass

    # ãƒ‡ãƒãƒƒã‚°ç”¨ãƒ­ã‚°ï¼ˆå¿…è¦ãªã‚‰ï¼‰
    if not home or not away:
        try:
            snippet = (row.inner_text() or "").strip().replace("\n", " ")[:200]
        except Exception:
            snippet = "<inner_text å–å¾—å¤±æ•—>"
        print(f"âš ï¸ ãƒãƒ¼ãƒ åå–å¾—å¤±æ•—: time={ktime}, snippet={snippet}")

    return ktime, home, away

def _get_match_row_link(row) -> str:
    """è©¦åˆè¡Œã‹ã‚‰ matchURL ã‚’æŠ½å‡º"""
    try:
        a = row.locator("a.eventRowLink[href*='/match/'][href*='?mid=']").first
        if a and a.count():
            href = a.get_attribute("href") or ""
            # ç›¸å¯¾ãƒ‘ã‚¹ã®å¯èƒ½æ€§ãŒã‚ã‚Œã°è£œå®Œ
            if href.startswith("http"):
                return href
            return "https://www.flashscore.co.jp" + href
    except:
        pass
    return ""

def collect_scheduled_matches_on_current_day(page) -> List[Dict[str, str]]:
    """
    ç¾åœ¨è¡¨ç¤ºä¸­ã®æ—¥ä»˜ï¼ˆé–‹å‚¬äºˆå®šã‚¿ãƒ–ï¼‰ã‹ã‚‰è©¦åˆæƒ…å ±ã‚’åé›†ã€‚
    ã“ã“ã§ã¯ HEADER_SCHEDULED ã®ã‚«ãƒ©ãƒ ã‚’ã™ã¹ã¦ä½œã‚‹ãŒã€é †ä½ãƒ»å¾—ç‚¹ç³»ã¯ç©ºæ¬„ã®ã¾ã¾ã€‚
    """
    # ã€Œé–‹å‚¬äºˆå®šã€ã‚¿ãƒ–ä¸Šã§ã€å¿µã®ãŸã‚ãƒ‹ãƒ¥ãƒ¼ã‚¹ãªã©ã§ã¯ãªã event__match ã‚’å¾…ã¤
    try:
        page.wait_for_selector("div.event__match", timeout=12000)
    except:
        log("âš ï¸ event__match ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã¾ã¾ç¶šè¡Œ")

    # ãƒªãƒ¼ã‚°ã‚’å±•é–‹
    expand_all_collapsed_leagues(page)

    # è©¦åˆè¡Œå–å¾—: scheduled ç”¨ã®ã‚¯ãƒ©ã‚¹ãŒã‚ã‚Œã°ãã‚Œã‚’å„ªå…ˆ
    rows = page.locator("div.event__match.event__match--scheduled")
    if rows.count() == 0:
        # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯: ã™ã¹ã¦ã®è©¦åˆè¡Œ
        rows = page.locator("div.event__match")
    n = rows.count()
    log(f"ğŸ¯ é–‹å‚¬äºˆå®šè©¦åˆ è¡Œæ•°: {n}")

    results: List[Dict[str, str]] = []
    seen_mids = set()

    now_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    for i in range(n):
        row = rows.nth(i)
        try:
            ktime, home, away = _get_match_row_teams_and_time(row)
            link = _get_match_row_link(row)
            cat  = _get_match_row_category(row)
            log(f"row:  {ktime}, {home}, {away}, {link}, {cat}")

            mid = extract_mid(link)
            if mid and mid in seen_mids:
                log(f"   â­ï¸ é‡è¤‡è©¦åˆ(mid={mid})ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                continue
            if mid:
                seen_mids.add(mid)

            d = {k: "" for k in HEADER_SCHEDULED}
            d["è©¦åˆå›½åŠã³ã‚«ãƒ†ã‚´ãƒª"] = cat
            d["è©¦åˆäºˆå®šæ™‚é–“"] = ktime
            d["ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ "] = home
            d["ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ "] = away
            d["è©¦åˆãƒªãƒ³ã‚¯æ–‡å­—åˆ—"] = link
            d["ãƒ‡ãƒ¼ã‚¿å–å¾—æ™‚é–“"] = now_str

            # ä»¥ä¸‹ã®é …ç›®ã¯ã€Œå…·ä½“çš„ãªå‡¦ç†ï¼ˆã©ã“ã‹ã‚‰å–ã‚‹ã‹ï¼‰ã‚’å¾Œã§è©°ã‚ã‚‹ã€å‰æã§ç©ºæ¬„ã®ã¾ã¾
            #   ãƒ›ãƒ¼ãƒ é †ä½ / ã‚¢ã‚¦ã‚§ãƒ¼é †ä½
            #   æœ€å¤§å¾—ç‚¹å–å¾—è€…
            #   ãƒ›ãƒ¼ãƒ /ã‚¢ã‚¦ã‚§ãƒ¼ å¾—ç‚¹ãƒ»å¤±ç‚¹ï¼ˆãƒ›ãƒ¼ãƒ æˆ¦/ã‚¢ã‚¦ã‚§ãƒ¼æˆ¦ï¼‰
            # â†’ ã“ã“ã§åˆ¥é€”ã€è©¦åˆè©³ç´°/ãƒãƒ¼ãƒ æƒ…å ±/é †ä½è¡¨ç­‰ã‹ã‚‰åŸ‹ã‚ã‚‹å‡¦ç†ã‚’å¾Œã§è¿½åŠ äºˆå®š

            results.append(d)

            log(f"   [{i+1}/{n}] {cat} | {ktime} | {home} vs {away} | mid={mid}")
        except Exception as e:
            log(f"   âš ï¸ è¡Œ{i}ã§ã‚¨ãƒ©ãƒ¼: {e}")
            continue

    log(f"âœ… å½“æ—¥åˆ† å–å¾—ä»¶æ•°: {len(results)}")
    return results

def click_next_day(page) -> bool:
    """
    ã€Œç¿Œæ—¥ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¦æ—¥ä»˜ã‚’1æ—¥é€²ã‚ã‚‹ã€‚
    æˆåŠŸã—ãŸã‚‰ True, è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° Falseã€‚
    """
    try:
        btn = page.locator("button.wcl-arrow_YpdN4[data-day-picker-arrow='next']").first
        if not btn or not btn.count():
            log("âš ï¸ ç¿Œæ—¥ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False
        btn.click(timeout=3000)
        log("â¡ï¸ ã€ç¿Œæ—¥ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã—ãŸ")
        # éåŒæœŸã§å†…å®¹ãŒå·®ã—æ›¿ã‚ã‚‹ã®ã§å°‘ã—å¾…æ©Ÿ
        time.sleep(1.0)
        try:
            page.wait_for_load_state("networkidle", timeout=8000)
        except:
            pass
        return True
    except Exception as e:
        log(f"âš ï¸ ç¿Œæ—¥ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯å¤±æ•—: {e}")
        return False

# ============== é †ä½è¡¨ ==============

def build_standings_url_from_match_url(match_url: str) -> str:
    """
    è©¦åˆãƒšãƒ¼ã‚¸URLã‚’é †ä½è¡¨ã‚¿ãƒ–ã®URLã«å¤‰æ›ã™ã‚‹ã€‚
    ä¾‹:
      /match/soccer/buhimba-.../police-.../?mid=xxx
      â†’ /match/soccer/buhimba-.../police-.../standings/?mid=xxx
    """
    if not match_url:
        return ""
    if "/standings/" in match_url:
        return match_url
    # "/?mid=" ã®ç›´å‰ã« "/standings" ã‚’å·®ã—è¾¼ã‚€
    return re.sub(r"/(\?mid=)", r"/standings/\1", match_url, count=1)

# ============== é †ä½è¡¨ã‹ã‚‰ãƒ›ãƒ¼ãƒ ã€ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ ã®é †ä½å–å¾— ==============

def get_team_ranks_from_standings_table(page, home_name: str, away_name: str):
    """
    ã™ã§ã«ã€Œé †ä½è¡¨ã€ã‚¿ãƒ–ï¼ˆã‚ªãƒ¼ãƒãƒ¼ã‚ªãƒ¼ãƒ«ï¼‰ãŒè¡¨ç¤ºã•ã‚Œã¦ã„ã‚‹ page ã‹ã‚‰ã€
    ãƒ›ãƒ¼ãƒ ï¼†ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ ã®é †ä½ï¼ˆrankï¼‰ã‚’å–å¾—ã™ã‚‹ã€‚

    æˆ»ã‚Šå€¤: (home_rank, away_rank)  â€»è¦‹ã¤ã‹ã‚‰ãªã‘ã‚Œã° "" ã®ã¾ã¾
    """
    home_name_norm = text_clean(home_name)
    away_name_norm = text_clean(away_name)

    home_rank = ""
    away_rank = ""

    # ãƒ†ãƒ¼ãƒ–ãƒ«æœ¬ä½“ã®è¡Œ
    rows = page.locator("div.ui-table__body > div.ui-table__row")
    n_rows = rows.count()

    for i in range(n_rows):
        row = rows.nth(i)
        try:
            team_elem = row.locator(".tableCellParticipant__name").first
            if not team_elem.count():
                continue
            team_name = text_clean(team_elem.text_content() or "")

            rank_elem = row.locator(".tableCellRank").first
            if not rank_elem.count():
                continue
            rank_text = text_clean(rank_elem.text_content() or "")
            # "4." ã¿ãŸã„ãªè¡¨è¨˜ã‚’ "4" ã«æ­£è¦åŒ–
            rank_text = rank_text.rstrip(".").strip()

            if not home_rank and team_name == home_name_norm:
                home_rank = rank_text
            if not away_rank and team_name == away_name_norm:
                away_rank = rank_text

            if home_rank and away_rank:
                break
        except:
            continue

    return home_rank, away_rank

# ============== 1è©¦åˆåˆ†ã®å›½ãƒªãƒ¼ã‚°,é †ä½ã‚’å–å¾—ã™ã‚‹é–¢æ•° ==============

def fetch_ranks_for_match(page, match_url: str, home_name: str, away_name: str):
    """
    è©¦åˆURLã‹ã‚‰é †ä½è¡¨ã‚¿ãƒ–ã«é£›ã³ã€
      - ãƒ›ãƒ¼ãƒ é †ä½
      - ã‚¢ã‚¦ã‚§ãƒ¼é †ä½
      - å›½å
      - ãƒªãƒ¼ã‚°åï¼ˆãƒ©ã‚¦ãƒ³ãƒ‰ä»˜ãï¼‰
    ã‚’å–å¾—ã™ã‚‹ã€‚

    æˆ»ã‚Šå€¤: (home_rank, away_rank, country, league)
    """
    if not match_url:
        return "", "", "", ""

    standings_url = build_standings_url_from_match_url(match_url)

    try:
        log(f"   ğŸ“Š é †ä½è¡¨å–å¾—: {standings_url}")
        page.goto(standings_url, timeout=25000, wait_until="domcontentloaded")

        # å¿µã®ãŸã‚ã€Œé †ä½è¡¨ã€ã‚¿ãƒ–ãŒé–‹ã„ã¦ã„ã‚‹ã‹ãƒã‚§ãƒƒã‚¯ã—ã¦ã€é–‹ã„ã¦ã„ãªã‘ã‚Œã°ã‚¯ãƒªãƒƒã‚¯
        try:
            standings_tab = page.locator(
                "a[data-analytics-alias='stats-detail'] button, "
                "a[href*='/standings/'] button"
            ).first
            if standings_tab and standings_tab.count():
                # data-selected="true" ã˜ã‚ƒãªã‘ã‚Œã°ã‚¯ãƒªãƒƒã‚¯
                selected = standings_tab.get_attribute("data-selected")
                if selected != "true":
                    standings_tab.click(timeout=3000)
                    page.wait_for_timeout(500)
        except:
            pass
        
        # ä¸Šéƒ¨ã®å›½ï¼†ãƒªãƒ¼ã‚°åã‚’å–å¾—
        country, league = get_country_and_league_from_match_page(page)

        # ãƒ†ãƒ¼ãƒ–ãƒ«ãŒæç”»ã•ã‚Œã‚‹ã®ã‚’å¾…ã¤
        page.wait_for_selector("div.ui-table__body div.ui-table__row", timeout=12000)

        # ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ©ãƒ³ã‚¯æŠ½å‡º
        home_rank, away_rank = get_team_ranks_from_standings_table(page, home_name, away_name)
        log(f"      â†’ rank: home={home_rank}, away={away_rank}, country={country}, league={league}")
        return home_rank, away_rank, country, league

    except Exception as e:
        log(f"   âš ï¸ é †ä½è¡¨å–å¾—å¤±æ•—: {e}")
        return "", "", "", ""

# ============== å…¨è©¦åˆã«å¯¾ã—ã¦é †ä½ã‚’åŸ‹ã‚ã‚‹ ==============

def fill_ranks_for_matches(ctx, matches: List[Dict[str, str]]):
    """
    ã™ã§ã«ã€Œé–‹å‚¬äºˆå®šã€ã§åé›†ã—ãŸè©¦åˆãƒªã‚¹ãƒˆã«å¯¾ã—ã¦ã€
    å„è©¦åˆãƒšãƒ¼ã‚¸ã®é †ä½è¡¨ã‹ã‚‰
      - ãƒ›ãƒ¼ãƒ é †ä½
      - ã‚¢ã‚¦ã‚§ãƒ¼é †ä½
      - è©¦åˆå›½åŠã³ã‚«ãƒ†ã‚´ãƒªï¼ˆå›½: ãƒªãƒ¼ã‚°ï¼‰
    ã‚’åŸ‹ã‚ã‚‹ã€‚
    """
    if not matches:
        return

    page = ctx.new_page()  # é †ä½è¡¨å°‚ç”¨ã‚¿ãƒ–

    for idx, m in enumerate(matches):
        url = m.get("è©¦åˆãƒªãƒ³ã‚¯æ–‡å­—åˆ—") or ""
        home = m.get("ãƒ›ãƒ¼ãƒ ãƒãƒ¼ãƒ ") or ""
        away = m.get("ã‚¢ã‚¦ã‚§ãƒ¼ãƒãƒ¼ãƒ ") or ""

        if not url or not home or not away:
            continue

        log(f"=== é †ä½å–å¾— {idx+1}/{len(matches)} ===")
        home_rank, away_rank, country, league = fetch_ranks_for_match(page, url, home, away)

        if home_rank:
            m["ãƒ›ãƒ¼ãƒ é †ä½"] = home_rank
        if away_rank:
            m["ã‚¢ã‚¦ã‚§ãƒ¼é †ä½"] = away_rank

        # å›½ï¼‹ãƒªãƒ¼ã‚°ãŒå–ã‚ŒãŸã‚‰ã€Œè©¦åˆå›½åŠã³ã‚«ãƒ†ã‚´ãƒªã€ã‚’ä¸Šæ›¸ã
        if country or league:
            if country and league:
                cat = f"{country}: {league}"
            else:
                cat = country or league
            m["è©¦åˆå›½åŠã³ã‚«ãƒ†ã‚´ãƒª"] = cat

    page.close()

# ============== å›½ãƒªãƒ¼ã‚°åã‚’å–å¾— ==============

def get_country_and_league_from_match_page(page):
    """
    è©¦åˆãƒšãƒ¼ã‚¸ï¼ˆã‚µãƒãƒªãƒ¼ / é †ä½è¡¨ã‚¿ãƒ–ï¼‰ã®ãƒ‘ãƒ³ããšã‹ã‚‰
    - å›½å
    - ãƒªãƒ¼ã‚°åï¼ˆï¼‹ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰
    ã‚’å–å¾—ã™ã‚‹ã€‚

    ä¾‹ï¼ˆãƒ‘ãƒ³ããšï¼‰:
      ã‚µãƒƒã‚«ãƒ¼ > ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ > ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚° - ãƒ©ã‚¦ãƒ³ãƒ‰ 14
    """
    country = ""
    league = ""

    try:
        # å¿µã®ãŸã‚ãƒ‘ãƒ³ããšãŒæç”»ã•ã‚Œã‚‹ã®ã‚’è»½ãå¾…ã¤
        try:
            page.wait_for_selector(
                "nav[data-testid='wcl-breadcrumbs'] span[data-testid='wcl-scores-overline-03']",
                timeout=3000
            )
        except Exception:
            # å¾…æ©Ÿå¤±æ•—ã—ã¦ã‚‚ç¶šè¡Œï¼ˆã‚ã¨ã§ count=0 ãªã‚‰åˆ†ã‹ã‚‹ï¼‰
            pass

        spans = page.locator(
            "nav[data-testid='wcl-breadcrumbs'] span[data-testid='wcl-scores-overline-03']"
        )
        count = spans.count()

        # ãƒ‡ãƒãƒƒã‚°ç”¨ï¼šä½•ãŒå–ã‚Œã¦ã„ã‚‹ã‹ç¢ºèªã—ãŸã„æ™‚ã«æœ‰åŠ¹åŒ–
        # print(f"[DEBUG] breadcrumb span count={count}")
        # for i in range(count):
        #     print(f"[DEBUG] span[{i}] = {text_clean(spans.nth(i).text_content() or '')}")

        if count == 0:
            return "", ""

        texts = []
        for i in range(count):
            txt = text_clean(spans.nth(i).text_content() or "")
            if txt:
                texts.append(txt)

        # æœŸå¾…ãƒ‘ã‚¿ãƒ¼ãƒ³:
        #   0: ã‚µãƒƒã‚«ãƒ¼
        #   1: ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰ï¼ˆå›½ï¼‰
        #   2: ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚° - ãƒ©ã‚¦ãƒ³ãƒ‰ 14ï¼ˆãƒªãƒ¼ã‚°ï¼‰
        #
        # ã¾ãšã€Œã‚µãƒƒã‚«ãƒ¼ã€ãŒå…ˆé ­ã«ã‚ã‚Œã°ã‚¹ã‚­ãƒƒãƒ—ã™ã‚‹
        start_idx = 0
        if texts and texts[0] == "ã‚µãƒƒã‚«ãƒ¼":
            start_idx = 1

        if len(texts) > start_idx:
            country = texts[start_idx]
        if len(texts) > start_idx + 1:
            league = texts[start_idx + 1]

    except Exception:
        # ä½•ã‹ã‚ã£ã¦ã‚‚ country, league ã¯ "" ã®ã¾ã¾è¿”ã™
        pass

    return country, league

# ============== ãƒ¡ã‚¤ãƒ³å…¥å£ ==============

def fetch_scheduled_matches(days) -> List[Dict[str, str]]:
    """
    Flashscore é–‹å‚¬äºˆå®šã‚¿ãƒ–ã‹ã‚‰ã€
      - ä»Šæ—¥ï¼ˆè¡¨ç¤ºä¸­ã®æ—¥ä»˜ï¼‰
      - ç¿Œæ—¥ä»¥é™ï¼ˆdays-1å›ã€ç¿Œæ—¥ã€ã‚’ã‚¯ãƒªãƒƒã‚¯ï¼‰
    ã®è©¦åˆæƒ…å ±ã‚’å–å¾—ã—ã¦ãƒªã‚¹ãƒˆã§è¿”ã™ã€‚

    days=2 â†’ ä»Šæ—¥ï¼‹ç¿Œæ—¥
    """
    all_results: List[Dict[str, str]] = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, slow_mo=70)
        ctx = browser.new_context(
            user_agent=("Mozilla/5.0 (Macintosh; Intel Mac OS X 13_6) "
                        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"),
            locale="ja-JP",
            timezone_id="Asia/Tokyo",
        )
        page = ctx.new_page()

        goto_football_top(page)

        # â‘  é–‹å‚¬äºˆå®šã‚¿ãƒ–ã‹ã‚‰å…¨è©¦åˆã‚’é›†ã‚ã‚‹
        for day_idx in range(days):
            if day_idx > 0:
                ok = click_next_day(page)
                if not ok:
                    log("â­ï¸ ç¿Œæ—¥ã¸ã®é·ç§»ãŒã§ããªã‹ã£ãŸãŸã‚ã€ä»¥é™ã®å–å¾—ã¯ã‚¹ã‚­ãƒƒãƒ—ã—ã¾ã™")
                    break
            log(f"==================== æ—¥ä»˜ã‚ªãƒ•ã‚»ãƒƒãƒˆ {day_idx} æ—¥ç›® ====================")
            day_results = collect_scheduled_matches_on_current_day(page)
            all_results.extend(day_results)

        # ã‚‚ã†é–‹å‚¬äºˆå®šã‚¿ãƒ–ã®ãƒšãƒ¼ã‚¸ã¯ä¸è¦ãªã®ã§é–‰ã˜ã¦ã‚‚OK
        page.close()

        # â‘¡ å„è©¦åˆãƒšãƒ¼ã‚¸ã®ã€Œé †ä½è¡¨ã€ã‹ã‚‰
        #    ãƒ›ãƒ¼ãƒ é †ä½ / ã‚¢ã‚¦ã‚§ãƒ¼é †ä½ / å›½ï¼†ãƒªãƒ¼ã‚°ã‚’åŸ‹ã‚ã‚‹
        fill_ranks_for_matches(ctx, all_results)

        browser.close()

    log(f"ğŸ‰ ç·å–å¾—ä»¶æ•°: {len(all_results)}")
    return all_results

if __name__ == "__main__":
    # ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¾‹
    matches = fetch_scheduled_matches(days=3)
    print(f"ç·ä»¶æ•°: {len(matches)}")
    if matches:
        # å…ˆé ­1ä»¶ã ã‘ã‚µãƒ³ãƒ—ãƒ«è¡¨ç¤º
        from pprint import pprint
        pprint(matches[0])
