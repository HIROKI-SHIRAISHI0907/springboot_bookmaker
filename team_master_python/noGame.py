# -*- coding: utf-8 -*-
from playwright.sync_api import sync_playwright
import time
import re
import datetime
import json
from typing import List, Dict, Optional, Tuple
from pathlib import Path

# bmData.py ã¨åŒæ§˜ã® outputs ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã‚’æƒ³å®š
SAVE_DIR_NOGAME = "/Users/shiraishitoshio/bookmaker/no_game"

# ========== å¯¾è±¡ãƒªãƒ¼ã‚°ãƒ»é™¤å¤–æ¡ä»¶ï¼ˆfutureData.py ã¨åŒã˜ï¼‰ ==========

CONTAINS_LIST = [
    "ã‚±ãƒ‹ã‚¢: ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚°", "ã‚³ãƒ­ãƒ³ãƒ“ã‚¢: ãƒ—ãƒªãƒ¡ãƒ¼ãƒ© A", "ã‚¿ãƒ³ã‚¶ãƒ‹ã‚¢: ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚°", "ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰: ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚°",
    "ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰: EFL ãƒãƒ£ãƒ³ãƒ”ã‚ªãƒ³ã‚·ãƒƒãƒ—", "ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰: EFL ãƒªãƒ¼ã‚° 1", "ã‚¨ãƒã‚ªãƒ”ã‚¢: ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚°", "ã‚³ã‚¹ã‚¿ãƒªã‚«: ãƒªãƒ¼ã‚¬ FPD",
    "ã‚¸ãƒ£ãƒã‚¤ã‚«: ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚°", "ã‚¹ãƒšã‚¤ãƒ³: ãƒ©ãƒ»ãƒªãƒ¼ã‚¬", "ãƒ–ãƒ©ã‚¸ãƒ«: ã‚»ãƒªã‚¨ A ãƒ™ã‚¿ãƒ¼ãƒ", "ãƒ–ãƒ©ã‚¸ãƒ«: ã‚»ãƒªã‚¨ B", "ãƒ‰ã‚¤ãƒ„: ãƒ–ãƒ³ãƒ‡ã‚¹ãƒªãƒ¼ã‚¬",
    "éŸ“å›½: K ãƒªãƒ¼ã‚° 1", "ä¸­å›½: ä¸­å›½ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒªãƒ¼ã‚°", "æ—¥æœ¬: J1 ãƒªãƒ¼ã‚°", "æ—¥æœ¬: J2 ãƒªãƒ¼ã‚°", "æ—¥æœ¬: J3 ãƒªãƒ¼ã‚°", "ã‚¤ãƒ³ãƒ‰ãƒã‚·ã‚¢: ã‚¹ãƒ¼ãƒ‘ãƒ¼ãƒªãƒ¼ã‚°",
    "ã‚ªãƒ¼ã‚¹ãƒˆãƒ©ãƒªã‚¢: A ãƒªãƒ¼ã‚°ãƒ»ãƒ¡ãƒ³", "ãƒãƒ¥ãƒ‹ã‚¸ã‚¢: ãƒãƒ¥ãƒ‹ã‚¸ã‚¢ï½¥ãƒ—ãƒ­ãƒªãƒ¼ã‚°", "ã‚¦ã‚¬ãƒ³ãƒ€: ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚°", "ãƒ¡ã‚­ã‚·ã‚³: ãƒªãƒ¼ã‚¬ MX",
    "ãƒ•ãƒ©ãƒ³ã‚¹: ãƒªãƒ¼ã‚°ãƒ»ã‚¢ãƒ³", "ã‚¹ã‚³ãƒƒãƒˆãƒ©ãƒ³ãƒ‰: ãƒ—ãƒ¬ãƒŸã‚¢ã‚·ãƒƒãƒ—", "ã‚ªãƒ©ãƒ³ãƒ€: ã‚¨ãƒ¼ãƒ«ãƒ‡ã‚£ãƒ“ã‚¸", "ã‚¢ãƒ«ã‚¼ãƒ³ãƒãƒ³: ãƒˆãƒ«ãƒã‚ªãƒ»ãƒ™ã‚¿ãƒ¼ãƒ",
    "ã‚¤ã‚¿ãƒªã‚¢: ã‚»ãƒªã‚¨ A", "ã‚¤ã‚¿ãƒªã‚¢: ã‚»ãƒªã‚¨ B", "ãƒãƒ«ãƒˆã‚¬ãƒ«: ãƒªãƒ¼ã‚¬ãƒ»ãƒãƒ«ãƒˆã‚¬ãƒ«", "ãƒˆãƒ«ã‚³: ã‚¹ãƒ¥ãƒšãƒ«ãƒ»ãƒªã‚°", "ã‚»ãƒ«ãƒ“ã‚¢: ã‚¹ãƒ¼ãƒšãƒ«ãƒªãƒ¼ã‚¬",
    "æ—¥æœ¬: WEãƒªãƒ¼ã‚°", "ãƒœãƒªãƒ“ã‚¢: LFPB", "ãƒ–ãƒ«ã‚¬ãƒªã‚¢: ãƒ‘ãƒ«ãƒ´ã‚¡ãƒ»ãƒªãƒ¼ã‚¬", "ã‚«ãƒ¡ãƒ«ãƒ¼ãƒ³: ã‚¨ãƒªãƒ¼ãƒˆ 1", "ãƒšãƒ«ãƒ¼: ãƒªãƒ¼ã‚¬ 1",
    "ã‚¨ã‚¹ãƒˆãƒ‹ã‚¢: ãƒ¡ã‚¹ã‚¿ãƒªãƒªãƒ¼ã‚¬", "ã‚¦ã‚¯ãƒ©ã‚¤ãƒŠ: ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚°", "ãƒ™ãƒ«ã‚®ãƒ¼: ã‚¸ãƒ¥ãƒ”ãƒ©ãƒ¼ï½¥ãƒ—ãƒ­ãƒªãƒ¼ã‚°", "ã‚¨ã‚¯ã‚¢ãƒ‰ãƒ«: ãƒªãƒ¼ã‚¬ãƒ»ãƒ—ãƒ­",
    "æ—¥æœ¬: YBC ãƒ«ãƒ´ã‚¡ãƒ³ã‚«ãƒƒãƒ—", "æ—¥æœ¬: å¤©çš‡æ¯"
]
UNDER_LIST  = ["U17", "U18", "U19", "U20", "U21", "U22", "U23", "U24", "U25"]
GENDER_LIST = ["å¥³å­"]
EXP_LIST    = ["ãƒãƒ«ãƒˆã‚¬ãƒ«: ãƒªãƒ¼ã‚¬ãƒ»ãƒãƒ«ãƒˆã‚¬ãƒ« 2", "ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰: ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚° 2", "ã‚¤ãƒ³ã‚°ãƒ©ãƒ³ãƒ‰: ãƒ—ãƒ¬ãƒŸã‚¢ãƒªãƒ¼ã‚° U18"]

VERBOSE = True

def log(msg: str):
    if VERBOSE:
        print(msg)

def text_clean(s: str) -> str:
    import re
    return re.sub(r"\s+", " ", (s or "")).strip()

def extract_mid(s: str) -> Optional[str]:
    if not s:
        return None
    s = str(s).strip()
    m = re.search(r"[?&#]mid=([A-Za-z0-9]+)", s)
    if m:
        return m.group(1)
    m = re.search(r"/match/([A-Za-z0-9]{6,20})(?:/|$)", s)
    if m:
        return m.group(1)
    return None

# ========== Flashscore ã€Œé–‹å‚¬äºˆå®šã€ã‚¿ãƒ–æ“ä½œ ==========

def goto_football_top(page):
    log("ğŸŒ Flashscore ãƒˆãƒƒãƒ—ã¸ã‚¢ã‚¯ã‚»ã‚¹...")
    page.goto("https://www.flashscore.co.jp/", timeout=45000, wait_until="domcontentloaded")

    # CookieãƒãƒŠãƒ¼
    try:
        page.locator("#onetrust-accept-btn-handler").click(timeout=2000)
        log("âœ… CookieãƒãƒŠãƒ¼ã‚’é–‰ã˜ã¾ã—ãŸ")
    except:
        pass

    # å¿µã®ãŸã‚ã€Œã‚µãƒƒã‚«ãƒ¼ã€ã‚’ã‚¯ãƒªãƒƒã‚¯
    try:
        soccer_btn = page.locator("a,button").filter(has_text="ã‚µãƒƒã‚«ãƒ¼").first
        if soccer_btn and soccer_btn.count():
            soccer_btn.click(timeout=4000)
            time.sleep(0.8)
    except:
        pass

    # ã€Œé–‹å‚¬äºˆå®šã€ã‚¿ãƒ–
    try:
        tab = page.locator("div.filters__tab[data-analytics-alias='scheduled']").first
        if tab and tab.count():
            tab.click(timeout=4000)
        else:
            tab = page.locator("div.filters__tab").filter(
                has_text=re.compile(r"(é–‹å‚¬äºˆå®š)")
            ).first
            tab.click(timeout=4000)
        log("âœ… ã€é–‹å‚¬äºˆå®šã€ã‚¿ãƒ–ã«åˆ‡ã‚Šæ›¿ãˆã¾ã—ãŸ")
    except Exception as e:
        log(f"âš ï¸ é–‹å‚¬äºˆå®šã‚¿ãƒ–åˆ‡ã‚Šæ›¿ãˆå¤±æ•—: {e}")

    try:
        page.wait_for_timeout(1000)
        page.wait_for_load_state("networkidle", timeout=8000)
    except:
        pass

def expand_all_collapsed_leagues(page):
    print("ğŸ“‚ æŠ˜ã‚ŠãŸãŸã¿ãƒªãƒ¼ã‚°ï¼ˆéè¡¨ç¤ºï¼‰ã‚’å±•é–‹ã—ã¾ã™...")
    btn_selector = (
        "button[data-testid='wcl-accordionButton']"
        "[aria-label='ãƒªãƒ¼ã‚°å…¨è©¦åˆ è¡¨ç¤º']"
    )
    max_loops = 200
    for _ in range(max_loops):
        btns = page.locator(btn_selector)
        count = btns.count()
        if count == 0:
            print("   âœ… ã™ã¹ã¦ã®æŠ˜ã‚ŠãŸãŸã¿ãƒªãƒ¼ã‚°ã‚’å±•é–‹ã—ã¾ã—ãŸ")
            return
        print(f"   æ®‹ã‚Šã€è¡¨ç¤ºã€ãƒœã‚¿ãƒ³æ•°: {count}")
        btn = btns.first
        try:
            btn.scroll_into_view_if_needed()
        except:
            pass
        try:
            btn.click(timeout=2000)
        except Exception as e:
            print(f"   âš ï¸ ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯å¤±æ•—: {e}")
            break
        page.wait_for_timeout(200)
    print("   âš ï¸ ãƒ«ãƒ¼ãƒ—ä¸Šé™ã€‚ã¾ã éè¡¨ç¤ºãŒæ®‹ã£ã¦ã„ã‚‹å¯èƒ½æ€§ã‚ã‚Šã€‚")

def click_next_day(page) -> bool:
    try:
        btn = page.locator("button.wcl-arrow_YpdN4[data-day-picker-arrow='next']").first
        if not btn or not btn.count():
            log("âš ï¸ ç¿Œæ—¥ãƒœã‚¿ãƒ³ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
            return False
        btn.click(timeout=3000)
        log("â¡ï¸ ã€ç¿Œæ—¥ã€ãƒœã‚¿ãƒ³ã‚’ã‚¯ãƒªãƒƒã‚¯ã—ã¾ã—ãŸ")
        time.sleep(1.0)
        try:
            page.wait_for_load_state("networkidle", timeout=8000)
        except:
            pass
        return True
    except Exception as e:
        log(f"âš ï¸ ç¿Œæ—¥ãƒœã‚¿ãƒ³ã‚¯ãƒªãƒƒã‚¯å¤±æ•—: {e}")
        return False

# ========== è©¦åˆè¡Œï¼ˆæ˜æ—¥ã®æ™‚é–“ãƒ»ãƒãƒ¼ãƒ ãƒ»ãƒªãƒ³ã‚¯ï¼‰å–å¾— ==========

def _get_match_row_teams_and_time(row):
    ktime = ""
    try:
        ktime = text_clean(row.locator(".event__time").first.text_content() or "")
    except:
        pass
    if not ktime:
        try:
            ktime = text_clean(
                row.locator(
                    "[data-testid='wcl-time'], "
                    "[data-testid='wcl-start-time'], "
                    "[data-testid='wcl-time-status']"
                ).first.text_content() or ""
            )
        except:
            pass

    home = ""
    away = ""

    # æ—§UI
    try:
        h = row.locator(".event__participant--home .event__participant--name").first
        a = row.locator(".event__participant--away .event__participant--name").first
        if h.count():
            home = text_clean(h.text_content() or "")
        if a.count():
            away = text_clean(a.text_content() or "")
    except:
        pass

    # ãã®ä»–ãƒ‘ã‚¿ãƒ¼ãƒ³
    if not home or not away:
        try:
            ps = row.locator(".event__participant .event__participant--name")
            if ps.count() >= 2:
                if not home:
                    home = text_clean(ps.first.text_content() or "")
                if not away:
                    away = text_clean(ps.last.text_content() or "")
        except:
            pass

    if not home or not away:
        try:
            h = row.locator(
                ".event__homeParticipant span.wcl-name_jjfMf, "
                ".event__homeParticipant [data-testid='wcl-scores-simple-text-01']"
            ).first
            a = row.locator(
                ".event__awayParticipant span.wcl-name_jjfMf, "
                ".event__awayParticipant [data-testid='wcl-scores-simple-text-01']"
            ).first
            if h and h.count() and not home:
                home = text_clean(h.text_content() or "")
            if a and a.count() and not away:
                away = text_clean(a.text_content() or "")
        except:
            pass

    if not home or not away:
        try:
            ps = row.locator(
                "[data-testid='wcl-matchRow-participant'] span.wcl-name_jjfMf, "
                "[data-testid='wcl-matchRow-participant'] [data-testid='wcl-scores-simple-text-01']"
            )
            n = ps.count()
            if n >= 2:
                if not home:
                    home = text_clean(ps.nth(0).text_content() or "")
                if not away:
                    away = text_clean(ps.nth(n - 1).text_content() or "")
        except:
            pass

    if not home or not away:
        try:
            imgs = row.locator("[data-testid='wcl-matchRow-participant'] img[data-testid='wcl-participantLogo']")
            n_img = imgs.count()
            if n_img >= 2:
                if not home:
                    home = text_clean(imgs.nth(0).get_attribute("alt") or "")
                if not away:
                    away = text_clean(imgs.nth(n_img - 1).get_attribute("alt") or "")
        except:
            pass

    if not home or not away:
        try:
            snippet = (row.inner_text() or "").strip().replace("\n", " ")[:200]
        except:
            snippet = "<inner_textå–å¾—å¤±æ•—>"
        print(f"âš ï¸ ãƒãƒ¼ãƒ åå–å¾—å¤±æ•—: time={ktime}, snippet={snippet}")

    return ktime, home, away

def _get_match_row_link(row) -> str:
    try:
        a = row.locator("a.eventRowLink[href*='/match/'][href*='?mid=']").first
        if a and a.count():
            href = a.get_attribute("href") or ""
            if href.startswith("http"):
                return href
            return "https://www.flashscore.co.jp" + href
    except:
        pass
    return ""

def get_current_match_date(page) -> Optional[datetime.date]:
    try:
        btn = page.locator("button[data-testid='wcl-dayPickerButton']").first
        if not btn or not btn.count():
            return None
        txt = text_clean(btn.inner_text() or "")
        m = re.search(r"(\d{2})/(\d{2})", txt)
        if not m:
            return None
        day = int(m.group(1))
        month = int(m.group(2))
        year = datetime.datetime.now().year
        return datetime.date(year, month, day)
    except:
        return None

def collect_scheduled_matches_on_current_day(page) -> List[Dict[str, str]]:
    """
    ç¾åœ¨è¡¨ç¤ºä¸­ã®æ—¥ä»˜ã®è©¦åˆä¸€è¦§ã‚’å–å¾—
    æˆ»ã‚Šå€¤: { 'datetime_str', 'home', 'away', 'url' } ã®ãƒªã‚¹ãƒˆ
    """
    try:
        page.wait_for_selector("div.event__match", timeout=12000)
    except:
        log("âš ï¸ event__match ãŒè¦‹ã¤ã‹ã‚‰ãªã„ã¾ã¾ç¶šè¡Œ")

    expand_all_collapsed_leagues(page)

    match_date = get_current_match_date(page)

    rows = page.locator("div.event__match.event__match--scheduled")
    if rows.count() == 0:
        rows = page.locator("div.event__match")
    n = rows.count()
    log(f"ğŸ¯ é–‹å‚¬äºˆå®šè©¦åˆ è¡Œæ•°: {n}")

    results: List[Dict[str, str]] = []
    seen_mids = set()
    now_str = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")

    for i in range(n):
        row = rows.nth(i)
        try:
            ktime, home, away = _get_match_row_teams_and_time(row)
            link = _get_match_row_link(row)

            if match_date and ktime:
                match_dt_str = f"{match_date.strftime('%Y-%m-%d')} {ktime}"
            else:
                match_dt_str = ktime

            mid = extract_mid(link)
            if mid and mid in seen_mids:
                log(f"   â­ï¸ é‡è¤‡è©¦åˆ(mid={mid})ã‚’ã‚¹ã‚­ãƒƒãƒ—")
                continue
            if mid:
                seen_mids.add(mid)

            d = {
                "datetime_str": match_dt_str,
                "home": home,
                "away": away,
                "url": link,
                "fetched_at": now_str,
            }
            results.append(d)
            log(f"   [{i+1}/{n}] | {match_dt_str} | {home} vs {away}")
        except Exception as e:
            log(f"   âš ï¸ è¡Œ{i}ã§ã‚¨ãƒ©ãƒ¼: {e}")
            continue

    log(f"âœ… å½“æ—¥åˆ† å–å¾—ä»¶æ•°: {len(results)}")
    return results

# ========== è©¦åˆãƒšãƒ¼ã‚¸ã‹ã‚‰ã€Œå›½: ãƒªãƒ¼ã‚°ã€å–å¾— & ãƒ•ã‚£ãƒ«ã‚¿ ==========

def get_country_and_league_from_match_page(page) -> Tuple[str, str]:
    country = ""
    league = ""
    try:
        try:
            page.wait_for_selector(
                "nav[data-testid='wcl-breadcrumbs'] span[data-testid='wcl-scores-overline-03']",
                timeout=3000
            )
        except:
            pass

        spans = page.locator(
            "nav[data-testid='wcl-breadcrumbs'] span[data-testid='wcl-scores-overline-03']"
        )
        count = spans.count()
        if count == 0:
            return "", ""

        texts = []
        for i in range(count):
            txt = text_clean(spans.nth(i).text_content() or "")
            if txt:
                texts.append(txt)

        start_idx = 0
        if texts and texts[0] == "ã‚µãƒƒã‚«ãƒ¼":
            start_idx = 1
        if len(texts) > start_idx:
            country = texts[start_idx]
        if len(texts) > start_idx + 1:
            league = texts[start_idx + 1]
    except:
        pass
    return country, league

def enrich_and_filter_by_league(ctx, matches: List[Dict[str, str]]) -> None:
    """
    å„è©¦åˆURLã¸ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã€Œå›½: ãƒªãƒ¼ã‚°ã€ã‚’ä»˜ä¸ã—ã€
    CONTAINS_LIST / Uç³» / å¥³å­ / ä¾‹å¤–ãƒªãƒ¼ã‚° ã§ãƒ•ã‚£ãƒ«ã‚¿ã™ã‚‹ã€‚
    çµæœã¯ matches ã‚’ã‚¤ãƒ³ãƒ—ãƒ¬ãƒ¼ã‚¹ã§æ›¸ãæ›ãˆï¼ˆå¯¾è±¡ã®ã¿æ®‹ã‚‹ï¼‰ã€‚
    """
    if not matches:
        return

    page = ctx.new_page()
    filtered: List[Dict[str, str]] = []

    for idx, m in enumerate(matches):
        url = m.get("url") or ""
        if not url:
            log("â­ï¸ URLãªã—è©¦åˆã‚’ã‚¹ã‚­ãƒƒãƒ—")
            continue

        log(f"=== ãƒªãƒ¼ã‚°å–å¾— {idx+1}/{len(matches)} ===")
        try:
            page.goto(url, timeout=25000, wait_until="domcontentloaded")
        except Exception as e:
            log(f"   âš ï¸ è©¦åˆãƒšãƒ¼ã‚¸é·ç§»å¤±æ•—: {e}")
            continue

        country, league = get_country_and_league_from_match_page(page)

        if country and league:
            category = f"{country}: {league}"
        else:
            category = country or league or ""

        if not category:
            log("â­ï¸ ã‚«ãƒ†ã‚´ãƒªå–å¾—å¤±æ•— â†’ é™¤å¤–")
            continue

        # å¯¾è±¡ãƒªãƒ¼ã‚°åˆ¤å®š
        if not any(c in category for c in CONTAINS_LIST):
            log(f"â­ï¸ å¯¾è±¡å¤–ãƒªãƒ¼ã‚°: {category}")
            continue

        # Uç³» / å¥³å­ / ä¾‹å¤–ãƒªãƒ¼ã‚°ã¯é™¤å¤–
        if (any(x in category for x in UNDER_LIST) or
            any(x in category for x in GENDER_LIST) or
            any(x in category for x in EXP_LIST)):
            log(f"ğŸš« é™¤å¤–ã‚«ãƒ†ã‚´ãƒª: {category}")
            continue

        m["category"] = category
        filtered.append(m)
        log(f"âœ… æ¡ç”¨: {category} | {m.get('home')} vs {m.get('away')}")

    page.close()
    matches[:] = filtered

# ========== ç¿Œæ—¥ã®ã€Œè©¦åˆãŒãªã„æ™‚é–“å¸¯ã€ã‚’è¨ˆç®— ==========

def _parse_match_datetime(dt_str: str) -> Optional[datetime.datetime]:
    if not dt_str:
        return None
    dt_str = str(dt_str).strip()
    for fmt in ("%Y-%m-%d %H:%M", "%Y/%m/%d %H:%M"):
        try:
            return datetime.datetime.strptime(dt_str, fmt)
        except ValueError:
            continue
    try:
        t = datetime.datetime.strptime(dt_str, "%H:%M").time()
        today = datetime.date.today()
        return datetime.datetime.combine(today, t)
    except ValueError:
        return None

def _calc_free_slots_for_date(
    start_of_day: datetime.datetime,
    end_of_day: datetime.datetime,
    match_datetimes: List[datetime.datetime],
    min_gap_minutes: int = 0
) -> List[Tuple[datetime.datetime, datetime.datetime]]:
    times = sorted(set(match_datetimes))
    free_slots: List[Tuple[datetime.datetime, datetime.datetime]] = []
    current = start_of_day

    for dt in times:
        if dt > current:
            gap_minutes = (dt - current).total_seconds() / 60
            if gap_minutes >= min_gap_minutes:
                free_slots.append((current, dt))
        if dt > current:
            current = dt

    if current < end_of_day:
        gap_minutes = (end_of_day - current).total_seconds() / 60
        if gap_minutes >= min_gap_minutes:
            free_slots.append((current, end_of_day))

    return free_slots

def get_free_slots_for_matches(matches: List[Dict[str, str]], min_gap_minutes: int = 0):
    """
    1æ—¥åˆ†ã®è©¦åˆï¼ˆdatetime_str ãŒåŒã˜æ—¥ä»˜ï¼‰ã‹ã‚‰ã€ãã®æ—¥ã®ç©ºãæ™‚é–“å¸¯ã‚’è¿”ã™ã€‚
    æˆ»ã‚Šå€¤: [(free_start_dt, free_end_dt), ...]
    """
    dts: List[datetime.datetime] = []
    for m in matches:
        dt = _parse_match_datetime(m.get("datetime_str", ""))
        if dt:
            dts.append(dt)

    if not dts:
        print("âš ï¸ æœ‰åŠ¹ãªè©¦åˆé–‹å§‹æ™‚åˆ»ãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return []

    # ã“ã®ã‚¹ã‚¯ãƒªãƒ—ãƒˆã§ã¯ã€Œç¿Œæ—¥1æ—¥åˆ†ã€ã—ã‹å–ã£ã¦ã„ãªã„æƒ³å®š
    target_date = dts[0].date()

    start_of_day = datetime.datetime.combine(target_date, datetime.time(0, 0))
    end_of_day   = start_of_day + datetime.timedelta(days=1)

    print(f"\nğŸ¯ å¯¾è±¡æ—¥: {target_date}\n")
    print("ğŸ“ å¯¾è±¡æ—¥ã®è©¦åˆé–‹å§‹æ™‚åˆ»ï¼ˆå¯¾è±¡ãƒªãƒ¼ã‚°ã®ã¿ï¼‰:")
    for dt in sorted(dts):
        print(" ãƒ»", dt.strftime("%Y-%m-%d %H:%M"))
    print()

    free_slots = _calc_free_slots_for_date(start_of_day, end_of_day, dts, min_gap_minutes)
    return free_slots

def convert_free_slots_to_ecs_slots(
    free_slots: List[Tuple[datetime.datetime, datetime.datetime]],
    post_match_buffer_minutes: int = 180,   # å‰ã®è©¦åˆå¾Œ 3æ™‚é–“
    pre_match_buffer_minutes: int = 30      # æ¬¡ã®è©¦åˆã®30åˆ†å‰ã«å†ç¨¼åƒ
) -> List[Tuple[datetime.datetime, datetime.datetime]]:
    """
    free_slotsï¼ˆè©¦åˆãŒ1ã¤ã‚‚ãªã„æ™‚é–“å¸¯ï¼‰ã‹ã‚‰ã€
    ECSã‚’åœæ­¢ã—ã¦ã„ã¦ã‚ˆã„æ™‚é–“å¸¯ã‚’è¨ˆç®—ã—ã¦è¿”ã™ã€‚

    å„ free_slot (free_start, free_end) ã«ã¤ã„ã¦:
      ecs_start = free_start + post_match_buffer_minutes
      ecs_end   = free_end   - pre_match_buffer_minutes

    ecs_start < ecs_end ã®ã¨ãã ã‘æœ‰åŠ¹ãªåœæ­¢ã‚¹ãƒ­ãƒƒãƒˆã¨ã—ã¦æ¡ç”¨ã€‚
    """
    ecs_slots: List[Tuple[datetime.datetime, datetime.datetime]] = []

    delta_post = datetime.timedelta(minutes=post_match_buffer_minutes)
    delta_pre  = datetime.timedelta(minutes=pre_match_buffer_minutes)

    for free_start, free_end in free_slots:
        ecs_start = free_start + delta_post
        ecs_end   = free_end   - delta_pre

        if ecs_start < ecs_end:
            ecs_slots.append((ecs_start, ecs_end))

    return ecs_slots

# ========== ãƒ¡ã‚¤ãƒ³ï¼šç¿Œæ—¥ã®å¯¾è±¡è©¦åˆ & ç©ºãæ™‚é–“å–å¾— ==========

def fetch_nextday_matches_and_free_slots(min_gap_minutes: int = 0):
    """
    Flashscore é–‹å‚¬äºˆå®šã‚¿ãƒ–ã‹ã‚‰
      - ç¿Œæ—¥ã®å¯¾è±¡è©¦åˆä¸€è¦§
      - ãã®æ—¥ã®ã€Œè©¦åˆãŒãªã„æ™‚é–“å¸¯ã€ä¸€è¦§
    ã‚’å–å¾—ã—ã¦è¿”ã™ã€‚
    """
    matches: List[Dict[str, str]] = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True, slow_mo=70)
        ctx = browser.new_context(
            user_agent=("Mozilla/5.0 (Macintosh; Intel Mac OS X 13_6) "
                        "AppleWebKit/537.36 (KHTML, like Gecko) Chrome/126.0.0.0 Safari/537.36"),
            locale="ja-JP",
            timezone_id="Asia/Tokyo",
        )
        page = ctx.new_page()

        goto_football_top(page)

        # ç¿Œæ—¥ã¸
        ok = click_next_day(page)
        if not ok:
            log("âŒ ç¿Œæ—¥ã«é€²ã‚ãªã‹ã£ãŸãŸã‚çµ‚äº†ã—ã¾ã™ã€‚")
            browser.close()
            return [], []

        log("==================== ç¿Œæ—¥ã®è©¦åˆã‚’å–å¾— ====================")
        day_results = collect_scheduled_matches_on_current_day(page)
        matches.extend(day_results)

        page.close()

        # è©¦åˆãƒšãƒ¼ã‚¸ã«ã‚¢ã‚¯ã‚»ã‚¹ã—ã¦ã€Œå›½: ãƒªãƒ¼ã‚°ã€ã‚’ä»˜ä¸ã—ãªãŒã‚‰ãƒ•ã‚£ãƒ«ã‚¿
        enrich_and_filter_by_league(ctx, matches)

        browser.close()

    log(f"ğŸ‰ ç¿Œæ—¥ãƒ»å¯¾è±¡ãƒªãƒ¼ã‚°ã®å–å¾—ä»¶æ•°: {len(matches)}")

    free_slots = get_free_slots_for_matches(matches, min_gap_minutes=min_gap_minutes)
    return matches, free_slots

# ========== ã‚¹ã‚¯ãƒªãƒ—ãƒˆã¨ã—ã¦å®Ÿè¡Œã•ã‚ŒãŸå ´åˆ ==========

if __name__ == "__main__":
    # freeã‚¹ãƒ­ãƒƒãƒˆã‚’ãã®ã¾ã¾å‡ºã™å ´åˆã®æœ€å°ã‚®ãƒ£ãƒƒãƒ—ï¼ˆåˆ†ï¼‰
    MIN_GAP_MINUTES = 0

    matches, free_slots = fetch_nextday_matches_and_free_slots(
        min_gap_minutes=MIN_GAP_MINUTES
    )

    print("==== ğŸ•’ ç¿Œæ—¥ã®ã€è©¦åˆãŒãªã„æ™‚é–“å¸¯ï¼ˆraw free slotsï¼‰ã€ ====")
    if not free_slots:
        print("ï¼ˆã‚¹ã‚­ãƒæ™‚é–“ãªã— / è©¦åˆãªã— / å–å¾—å¤±æ•—ï¼‰")
    else:
        for start, end in free_slots:
            print(f"  {start.strftime('%Y-%m-%d %H:%M')} ã€œ {end.strftime('%H:%M')}")

    # ğŸ”¹ free_slots ã‹ã‚‰ ECSåœæ­¢æ™‚é–“å¸¯ã‚’è¨ˆç®—
    ecs_slots = convert_free_slots_to_ecs_slots(
        free_slots,
        post_match_buffer_minutes=180,   # è©¦åˆå¾Œ 3æ™‚é–“ã¯å‹•ã‹ã™
        pre_match_buffer_minutes=30      # æ¬¡ã®è©¦åˆã®30åˆ†å‰ã«ã¯å†ç¨¼åƒ
    )

    print("\n==== ğŸ“´ ECS åœæ­¢ã—ã¦ã„ã¦ã‚ˆã„æ™‚é–“å¸¯ï¼ˆderived from free slotsï¼‰ ====")
    if not ecs_slots:
        print("ï¼ˆåœæ­¢å¯èƒ½ãªæ™‚é–“å¸¯ã¯ã‚ã‚Šã¾ã›ã‚“ï¼‰")
    else:
        for start, end in ecs_slots:
            print(f"  {start.strftime('%Y-%m-%d %H:%M')} ã€œ {end.strftime('%H:%M')}")

    # ğŸ”¹ JSON_FREE_SLOTS ã¯ã€ŒECSåœæ­¢æ™‚é–“ã€ã‚’å‡ºåŠ›ã™ã‚‹ã‚ˆã†ã«å¤‰æ›´
    json_slots = [
        {
            "start": start.isoformat(),
            "end": end.isoformat(),
        }
        for start, end in ecs_slots
    ]
    print("\n==== JSON_FREE_SLOTS (ECS stop intervals) ====")
    print(json.dumps(json_slots, ensure_ascii=False))

    output_dir_path = Path(SAVE_DIR_NOGAME)
    output_dir_path.mkdir(parents=True, exist_ok=True)

    # ğŸ”¹ ãƒ•ã‚¡ã‚¤ãƒ«å
    output_file = "ecs_slots.json"

    # ğŸ”¹ ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã¨ãƒ•ã‚¡ã‚¤ãƒ«åã‚’é€£çµ
    output_path = output_dir_path / output_file

    # ğŸ”¹ JSONãƒ•ã‚¡ã‚¤ãƒ«ã¨ã—ã¦ä¿å­˜
    with open(output_path, "w", encoding="utf-8") as f:
        json.dump(json_slots, f, ensure_ascii=False, indent=2)

    print(f"JSONå‡ºåŠ›å®Œäº†: {output_path}")

